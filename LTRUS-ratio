from scipy.optimize import differential_evolution
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
import random
# from SMOTE_backup import Smote
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn import neighbors
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score
import time
import csv
import warnings
from sklearn.metrics import confusion_matrix, matthews_corrcoef
from sklearn.neural_network import MLPClassifier
from sklearn import tree
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import GridSearchCV
np.set_printoptions(suppress=True)
warnings.filterwarnings('ignore')
classifier = "knn"
# tuned_parameters = {'n_neighbors': [1, 3, 5, 7, 9, 11, 13]}

skf = StratifiedKFold(n_splits=5)


def fit(bound, *param):
    de_dataset = []
    de_ratio = bound[-1]
    # if de_ratio < 1:
    #     de_ratio = 0.5
    # elif 1 <= de_ratio < 2:
    #     de_ratio = 1
    # elif 2 <= de_ratio < 3:
    #     optimal_ratio = 2
    # elif 3 <= de_ratio < 5:
    #     optimal_ratio = 4
    bound = bound[0:-1]
    for de_i in param:
        de_dataset.append(de_i)

    de_dataset = np.array(de_dataset)
    de_x = de_dataset
    de_y = de_dataset[:, -1]
    de_total_mcc = 0
    for train, test in skf.split(de_x, de_y):
        de_train_x = de_x[train]
        de_train_y = de_y[train]

        for sub_train, sub_test in skf.split(de_train_x, de_train_y):
            de_sub_test_x = de_train_x[sub_test]
            de_sub_test_y = de_sub_test_x[:, -1]
            de_sub_test_x = de_sub_test_x[:, 0:-1]

            de_sub_train_x = de_train_x[sub_train]
            de_sub_defect_x = de_sub_train_x[de_sub_train_x[:, -1] > 0]
            # de_sub_defect_x = de_sub_defect_x[:, 0:-1]
            de_sub_clean_x = de_sub_train_x[de_sub_train_x[:, -1] == 0]
            # print(de_sub_clean_x)
            # de_sub_clean_x = de_sub_clean_x[:, 0:-1]
            de_need_number = int((de_ratio * len(de_sub_clean_x) - len(de_sub_defect_x)) / de_ratio)  # len(de_sub_clean_x) - len(de_sub_defect_x) * de_ratio
            de_sub_clean_x[:, 0:-1] = bound * de_sub_clean_x[:, 0:-1]
            de_total_sum = np.sum(de_sub_clean_x[:, 0:-1], axis=1)
            de_sub_clean_x = np.c_[de_sub_clean_x, de_total_sum]
            de_sub_clean_x = de_sub_clean_x[np.argsort(-de_sub_clean_x[:, -1])]
            de_sub_clean_x = np.delete(de_sub_clean_x, [a for a in range(de_need_number)], axis=0)
            de_sub_clean_x = de_sub_clean_x[:, 0:-1]
            de_sub_clean_x[:, 0:-1] = de_sub_clean_x[:, 0:-1] / bound
            de_sub_train_x = np.r_[de_sub_clean_x, de_sub_defect_x]
            de_sub_train_y = de_sub_train_x[:, -1]
            de_sub_train_x = de_sub_train_x[:, 0:-1]
            de_clf = classifier_for_selection[classifier]
            de_clf.fit(de_sub_train_x, de_sub_train_y)
            de_predict_result = de_clf.predict(de_sub_test_x)
            de_mcc = matthews_corrcoef(de_sub_test_y, de_predict_result)
            de_total_mcc = de_total_mcc + de_mcc

    de_average_mcc = de_total_mcc / 25
    de_average_mcc = - de_average_mcc
    return de_average_mcc


for iteration in range(10):
    single = open('D:\\ltrus to reliability\\defect ratio\\'+classifier+'radius based oversampling '+str(iteration)+'.csv', 'w',
                  newline='')
    single_writer = csv.writer(single)
    single_writer.writerow(["inputfile", "mcc", "auc", "balance", "fmeasure", "precision", "pd", "pf", "defect ratio"])
    for inputfile in os.listdir("D:\\datasets\\all\\only first version"):
        print("inputfile:", inputfile)
        start_time = time.asctime(time.localtime(time.time()))
        print("start time:", start_time)
        if inputfile == "synapse-1.0.csv" or inputfile == "jedit-4.3.csv" or inputfile == "synapse-1.1.csv":
            continue

        dataset = pd.read_csv("D:\\datasets\\all\\only first version\\" + inputfile)
        dataset = dataset.drop(columns="name")
        dataset = dataset.drop(columns="version")
        dataset = dataset.drop(columns="name.1")
        total_number = len(dataset)
        defect_ratio = len(dataset[dataset["bug"] > 0]) / total_number
        if defect_ratio > 0.45:  #
            print(inputfile, " defect ratio larger than 0.45")
            continue

        for z in range(total_number):
            if dataset.loc[z, "bug"] > 0:
                dataset.loc[z, "bug"] = 1
        cols = list(dataset.columns)
        for col in cols:
            column_max = dataset[col].max()
            column_min = dataset[col].min()
            dataset[col] = (dataset[col] - column_min) / (column_max - column_min)

        dataset = np.array(dataset)

        # validation_train_x = dataset[:, 0:-1]
        # validation_train_y = dataset[:, -1]
        #
        # validation_clf = GridSearchCV(neighbors.KNeighborsClassifier(), tuned_parameters, cv=5, n_jobs=-1)
        # validation_clf.fit(validation_train_x, validation_train_y)
        # best_parameter = validation_clf.best_params_
        # best_k = best_parameter["n_neighbors"]

        classifier_for_selection = {"knn": neighbors.KNeighborsClassifier(), "svm": svm.SVC(),
                                    "rf": RandomForestClassifier(random_state=0),
                                    "dt": tree.DecisionTreeClassifier(random_state=0),
                                    "lr": LogisticRegression(random_state=0), "nb": GaussianNB()}

        bound = [(-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1),
                 (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1), (-1, 1),
                 (-1, 1), (-1, 1), (-1, 1), (-1, 1), (0, 1)]

        optimal_result = differential_evolution(fit, bound, args=dataset, popsize=10, maxiter=20, mutation=0.3,
                                                recombination=0.9, disp=True)
        optimal_result = optimal_result.x
        optimal_weight = optimal_result[0:-1]
        optimal_ratio = optimal_result[-1]
        # if optimal_ratio < 1:
        #     optimal_ratio = 0.5
        # elif 1 <= optimal_ratio < 2:
        #     optimal_ratio = 1
        # elif 2 <= optimal_ratio < 3:
        #     optimal_ratio = 2
        # elif 3 <= optimal_ratio < 5:
        #     optimal_ratio = 4

        y = dataset[:, -1]
        x = dataset

        total_auc = 0
        total_balance = 0
        total_fmeasure = 0
        total_precision = 0
        total_recall = 0
        total_pf = 0
        total_mcc = 0

        for train, test in skf.split(x, y):
            test_x = x[test]
            test_y = test_x[:, -1]
            test_x = test_x[:, 0:-1]

            train_x = x[train]

            defect_x = train_x[train_x[:, -1] > 0]
            clean_x = train_x[train_x[:, -1] == 0]
            need_number = int((optimal_ratio * len(clean_x) - len(defect_x)) / optimal_ratio)  # len(clean_x) - len(defect_x) * optimal_ratio

            clean_x[:, 0:-1] = optimal_weight * clean_x[:, 0:-1]
            total_sum = np.sum(clean_x[:, 0:-1], axis=1)
            clean_x = np.c_[clean_x, total_sum]
            clean_x = clean_x[np.argsort(-clean_x[:, -1])]
            clean_x = np.delete(clean_x, [a for a in range(need_number)], axis=0)
            clean_x = clean_x[:, 0:-1]
            clean_x[:, 0:-1] = clean_x[:, 0:-1] / optimal_weight
            train_x = np.r_[clean_x, defect_x]
            train_y = train_x[:, -1]
            train_x = train_x[:, 0:-1]
            clf = classifier_for_selection[classifier]
            clf.fit(train_x, train_y)
            predict_result = clf.predict(test_x)

            auc = roc_auc_score(test_y, predict_result)
            total_auc = total_auc + auc

            mcc = matthews_corrcoef(test_y, predict_result)
            total_mcc = total_mcc + mcc

            fmeasure = f1_score(test_y, predict_result)
            total_fmeasure = total_fmeasure + fmeasure

            true_negative, false_positive, false_negative, true_positive = confusion_matrix(test_y,
                                                                                            predict_result).ravel()

            recall = recall_score(test_y, predict_result)
            total_recall = total_recall + recall

            pf = false_positive / (true_negative + false_positive)
            total_pf = total_pf + pf

            balance = 1 - (((0 - pf) ** 2 + (1 - recall) ** 2) / 2) ** 0.5
            total_balance = total_balance + balance

            precision = precision_score(test_y, predict_result)
            total_precision = total_precision + precision

        average_auc = total_auc / 5
        average_balance = total_balance / 5
        average_fmeasure = total_fmeasure / 5
        average_precision = total_precision / 5
        average_recall = total_recall / 5
        average_pf = total_pf / 5
        average_mcc = total_mcc / 5
        single_writer.writerow(
            [inputfile, average_mcc, average_auc, average_balance, average_fmeasure, average_precision, average_recall, average_pf, optimal_ratio])
        print("final auc: ", average_auc)
        print("end time: ", time.asctime(time.localtime(time.time())))
        print("--------------------------------------")
